fold: 0 - cp:1 train: 0.797882297882298 test: f1=0.5151299900554056, acc=0.8003509798186604
fold: 0 - cp:2 train: 0.8182695682695682 test: f1=0.4949316170555109, acc=0.8163790582041532
fold: 0 - cp:3 train: 0.8360828360828361 test: f1=0.6888314247013914, acc=0.8521789997075169
fold: 0 - cp:4 train: 0.8256698256698257 test: f1=0.6542432636615462, acc=0.8393682363264112
fold: 0 - cp:5 train: 0.8292675792675792 test: f1=0.6700748129675811, acc=0.8452178999707517
fold: 0 - cp:6 train: 0.8947876447876447 test: f1=0.7833376321898375, acc=0.9017256507750804
fold: 0 - cp:7 train: 0.9152041652041651 test: f1=0.8428927680798005, acc=0.9262942380813103
fold: 0 - cp:8 train: 0.9171346671346671 test: f1=0.8216216216216216, acc=0.9189236618894414
fold: 0 - cp:9 train: 0.913156663156663 test: f1=0.8335817188276206, acc=0.9216145071658379
fold: 0 - cp:10 train: 0.9143559143559143 test: f1=0.8396335956650756, acc=0.9272886809008482
fold: 0 - cp:11 train: 0.9595179595179595 test: f1=0.9129895884977689, acc=0.9589353612167301
fold: 0 - cp:12 train: 0.9644612144612145 test: f1=0.9351851851851851, acc=0.9688797894121088
fold: 0 - cp:13 train: 0.9805487305487306 test: f1=0.9647544968400582, acc=0.9830359754314127
fold: 0 - cp:14 train: 0.97999297999298 test: f1=0.9670622426737708, acc=0.984088914887394
fold: 0 - cp:15 train: 0.98008073008073 test: f1=0.9689800844900421, acc=0.9849663644340451
fold: 0 - cp:16 train: 0.9818064818064818 test: f1=0.9661016949152543, acc=0.9836209417958467
fold: 0 - cp:17 train: 0.9807827307827308 test: f1=0.9653249272550921, acc=0.9832699619771863
fold: 0 - cp:18 train: 0.9807827307827308 test: f1=0.9608152371709329, acc=0.9811055864287803
fold: 0 - cp:19 train: 0.9793494793494794 test: f1=0.9672170956775133, acc=0.9842059081602808
fold: 1 - cp:1 train: 0.811319267888056 test: f1=0.5511355815554027, acc=0.8092313092313093
fold: 1 - cp:2 train: 0.8175490724332558 test: f1=0.5442574981711777, acc=0.8177723177723177
fold: 1 - cp:3 train: 0.8255337692340501 test: f1=0.6155679110405083, acc=0.8301158301158301
fold: 1 - cp:4 train: 0.8229012871326862 test: f1=0.6276923076923077, acc=0.8301158301158301
fold: 1 - cp:5 train: 0.8234572053594046 test: f1=0.5405238828967642, acc=0.8255528255528255
fold: 1 - cp:6 train: 0.8862827778948509 test: f1=0.7942942942942943, acc=0.9038259038259038
fold: 1 - cp:7 train: 0.9171685640450264 test: f1=0.8527245949926362, acc=0.9297999297999298
fold: 1 - cp:8 train: 0.9147995409401586 test: f1=0.85012285012285, acc=0.9286299286299287
fold: 1 - cp:9 train: 0.9152384658935899 test: f1=0.8447937131630648, acc=0.926055926055926
fold: 1 - cp:10 train: 0.9126061001353468 test: f1=0.8453407848378083, acc=0.9255294255294255
fold: 1 - cp:11 train: 0.957794647575883 test: f1=0.9239795281487955, acc=0.9643734643734644
fold: 1 - cp:12 train: 0.9624158065898823 test: f1=0.9420112551994128, acc=0.9722709722709723
fold: 1 - cp:13 train: 0.9818075323164233 test: f1=0.9741733043688149, acc=0.9874809874809874
fold: 1 - cp:14 train: 0.9819829811640762 test: f1=0.9716638411237588, acc=0.9863109863109863
fold: 1 - cp:15 train: 0.9833284311817301 test: f1=0.9753146176185866, acc=0.9880659880659881
fold: 1 - cp:16 train: 0.9805204557485793 test: f1=0.9751785930500061, acc=0.988007488007488
fold: 1 - cp:17 train: 0.9835624040408786 test: f1=0.9776861508610236, acc=0.9892359892359892
fold: 1 - cp:18 train: 0.9819536969162612 test: f1=0.9726842296952773, acc=0.9868374868374868
fold: 1 - cp:19 train: 0.9815151996948908 test: f1=0.9760058167716917, acc=0.9884169884169884
fold: 2 - cp:1 train: 0.7961857961857962 test: f1=0.5070380797155134, acc=0.8053816905527932
fold: 2 - cp:2 train: 0.8155493155493156 test: f1=0.5759573572731098, acc=0.8231646680315882
fold: 2 - cp:3 train: 0.8218380718380718 test: f1=0.6076230076230077, acc=0.8343960222287219
fold: 2 - cp:4 train: 0.8193518193518193 test: f1=0.5773047605350208, acc=0.8280783854928342
fold: 2 - cp:5 train: 0.822949572949573 test: f1=0.6518446127534815, acc=0.8332845861362972
fold: 2 - cp:6 train: 0.887007137007137 test: f1=0.8045550191855427, acc=0.9076338110558643
fold: 2 - cp:7 train: 0.9184216684216685 test: f1=0.8430203676105316, acc=0.9260602515355367
fold: 2 - cp:8 train: 0.916081666081666 test: f1=0.8431720293894097, acc=0.9275811640830652
fold: 2 - cp:9 train: 0.9145606645606645 test: f1=0.837155669442665, acc=0.9256507750804329
fold: 2 - cp:10 train: 0.9126301626301626 test: f1=0.8360737419033383, acc=0.9230184264404797
fold: 2 - cp:11 train: 0.9595179595179595 test: f1=0.9331521067589275, acc=0.9683533196841182
fold: 2 - cp:12 train: 0.9613607113607113 test: f1=0.937110758334351, acc=0.9698742322316467
fold: 2 - cp:13 train: 0.9788522288522289 test: f1=0.9639399806389158, acc=0.9825680023398654
fold: 2 - cp:14 train: 0.9781502281502281 test: f1=0.9667432579513847, acc=0.9839134249780638
fold: 2 - cp:15 train: 0.9810752310752311 test: f1=0.969726443768997, acc=0.9854343375255923
fold: 2 - cp:16 train: 0.9804024804024805 test: f1=0.9659090909090908, acc=0.98350394852296
fold: 2 - cp:17 train: 0.9798759798759799 test: f1=0.9706168042739194, acc=0.9858438139806961
fold: 2 - cp:18 train: 0.9804902304902305 test: f1=0.967553773240977, acc=0.984381398069611
fold: 2 - cp:19 train: 0.9807242307242308 test: f1=0.9704814904427777, acc=0.9857268207078093
fold: 3 - cp:1 train: 0.8130738487547098 test: f1=0.5548049083138012, acc=0.8111033111033111
fold: 3 - cp:2 train: 0.8209415865007816 test: f1=0.5655703866795101, acc=0.8153153153153153
fold: 3 - cp:3 train: 0.8312665936086621 test: f1=0.6386026639859261, acc=0.8317538317538318
fold: 3 - cp:4 train: 0.8235448801663121 test: f1=0.6568284142071035, acc=0.8394758394758395
fold: 3 - cp:5 train: 0.8248318403910355 test: f1=0.6390354182366239, acc=0.8318708318708319
fold: 3 - cp:6 train: 0.892863370635949 test: f1=0.7828432002054706, acc=0.9010764010764011
fold: 3 - cp:7 train: 0.919186918718973 test: f1=0.8463564530289728, acc=0.9283374283374284
fold: 3 - cp:8 train: 0.9198304398936126 test: f1=0.8363311646893736, acc=0.924944424944425
fold: 3 - cp:9 train: 0.9162328950291047 test: f1=0.8378550503120622, acc=0.9255294255294255
fold: 3 - cp:10 train: 0.919654895233978 test: f1=0.8386853988961364, acc=0.9247689247689248
fold: 3 - cp:11 train: 0.9555717137900105 test: f1=0.9265853658536585, acc=0.9647829647829648
fold: 3 - cp:12 train: 0.9673296506766325 test: f1=0.94169202678028, acc=0.971978471978472
fold: 3 - cp:13 train: 0.9821292757944606 test: f1=0.9697262091424437, acc=0.9853164853164853
fold: 3 - cp:14 train: 0.9832407769059618 test: f1=0.973378509196515, acc=0.9871299871299871
fold: 3 - cp:15 train: 0.9821586113701228 test: f1=0.9750030189590628, acc=0.987890487890488
fold: 3 - cp:16 train: 0.9830360472323505 test: f1=0.9754157628344179, acc=0.9880659880659881
fold: 3 - cp:17 train: 0.9838256816789807 test: f1=0.9753979739507959, acc=0.9880659880659881
fold: 3 - cp:18 train: 0.9808716716765384 test: f1=0.9739193431538276, acc=0.9873639873639873
fold: 3 - cp:19 train: 0.981836703642974 test: f1=0.9723463349836976, acc=0.9866034866034866
fold: 0 - cp:17 train: 0.988007799805005 test: f1=0.9830713422007256, acc=0.9918104708979234
fold: 1 - cp:17 train: 0.9893077673058175 test: f1=0.9775621588841722, acc=0.9891781222579702
fold: 2 - cp:17 train: 0.9891452713682158 test: f1=0.9709443099273609, acc=0.9859608072535829
fold: 3 - cp:17 train: 0.9900227494312641 test: f1=0.9804878048780488, acc=0.9906405381690553
fold: 4 - cp:17 train: 0.9897627559311017 test: f1=0.9789029535864978, acc=0.9897630886224043
fold: 5 - cp:17 train: 0.9895352616184596 test: f1=0.9783393501805054, acc=0.9894706054401872
fold: 6 - cp:17 train: 0.9897627559311017 test: f1=0.9806529625151149, acc=0.9906405381690553
fold: 7 - cp:17 train: 0.9883977900552485 test: f1=0.9753753753753754, acc=0.9880081895291021
fold: 8 - cp:17 train: 0.9900227494312641 test: f1=0.9823278488726387, acc=0.9915179877157063
fold: 9 - cp:17 train: 0.989503058070072 test: f1=0.9793939393939394, acc=0.9900526623756583



PC4
Features:
	workclass_Local-gov workclass_Never-worked
	workclass_Never-worked
	occupation_Armed-Forces
	workclass_Without-pay

PC9
Features:
	workclass_Local-gov workclass_Never-workeddot: graph is too large for cairo-renderer bitmaps. Scaling by 0.355904 to fit

	workclass_Never-worked
	workclass_Without-pay
	occupation_Armed-Forces

PC8
Features:
	workclass_Local-gov workclass_Never-worked
	workclass_?^2
	workclass_Never-worked
	marital-status_Married-AF-spouse

PC2
Features:
	workclass_Local-gov workclass_Never-worked
	workclass_Never-worked
	occupation_Sales
	race_Other

PC14
Features:
	workclass_Local-gov workclass_Never-worked
	income
	workclass_Never-worked
	occupation_Armed-Forces

PC3
Features:
	workclass_Local-gov workclass_Never-worked
	occupation_Armed-Forces
	marital-status_Married-spouse-absent
	workclass_Without-pay

PC10
Features:
	workclass_Local-gov workclass_Never-worked
	workclass_Never-worked
	marital-status_Married-AF-spouse
	occupation_Armed-Forces

PC16
Features:
	workclass_Local-gov workclass_Never-worked
	workclass_Without-pay
	occupation_Armed-Forces
	marital-status_Married-AF-spouse

PC5
Features:
	workclass_Local-gov workclass_Never-worked
	marital-status_Married-AF-spouse
	workclass_Never-worked
	workclass_Without-pay

PC17
Features:
	workclass_Local-gov workclass_Never-worked
	workclass_Never-worked^2
	race_Amer-Indian-Eskimo
	occupation_Armed-Forces

PC7
Features:
	workclass_Local-gov workclass_Never-worked
	workclass_Without-pay
	workclass_Never-worked
	occupation_Armed-Forces

PC15
Features:
	workclass_Local-gov workclass_Never-worked
	workclass_Never-worked
	workclass_Without-pay
	marital-status_Married-AF-spouse

PC6
Features:
	workclass_Local-gov workclass_Never-worked
	workclass_Never-worked
	workclass_Without-pay
	marital-status_Married-AF-spouse

PC12
Features:
	workclass_Local-gov workclass_Never-worked
	workclass_Without-pay
	marital-status_Married-AF-spouse
	workclass_? workclass_Federal-gov

PC13
Features:
	workclass_Local-gov workclass_Never-worked
	workclass_Never-worked
	occupation_Priv-house-serv
	occupation_Armed-Forces

PC11
Features:
	workclass_Local-gov workclass_Never-worked
	workclass_Never-worked
	occupation_Transport-moving
	occupation_Armed-Forces

PC1
Features:
	workclass_Local-gov workclass_Never-worked
	occupation_Armed-Forces
	occupation_Tech-support
	workclass_Without-pay

Normalized confusion matrix
[[9.99228395e-01 7.71604938e-04]
 [6.05326877e-03 9.93946731e-01]]

              precision    recall  f1-score   support

           0       1.00      1.00      1.00      2592
           1       1.00      0.99      1.00       826

    accuracy                           1.00      3418
   macro avg       1.00      1.00      1.00      3418
weighted avg       1.00      1.00      1.00      3418

Traceback (most recent call last):
  File "decision-tree-f1-98-acc-99-auc-99.py", line 386, in <module>
    sklearn.experimental.dump(best_model, 'lgr.sklearn.experimental')
AttributeError: module 'sklearn' has no attribute 'experimental'
