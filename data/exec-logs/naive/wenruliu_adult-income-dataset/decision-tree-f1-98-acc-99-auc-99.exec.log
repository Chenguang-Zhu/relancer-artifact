fold: 0 - cp:1 train: 0.8075640575640575 test: f1=0.5450068399452804, acc=0.8054401871892366
fold: 0 - cp:2 train: 0.8183573183573184 test: f1=0.559155130583702, acc=0.8193038900263235
fold: 0 - cp:3 train: 0.8201415701415701 test: f1=0.6139432350509783, acc=0.8360924246855805
fold: 0 - cp:4 train: 0.824002574002574 test: f1=0.6543778801843319, acc=0.8376718338695525
fold: 0 - cp:5 train: 0.8254943254943254 test: f1=0.6620217887002786, acc=0.8439309739689967
fold: 0 - cp:6 train: 0.8895811395811396 test: f1=0.7969905636317265, acc=0.9068733547821001
fold: 0 - cp:7 train: 0.9177489177489178 test: f1=0.8361524867457711, acc=0.924071365896461
fold: 0 - cp:8 train: 0.9183924183924185 test: f1=0.8465530022238695, acc=0.9273471775372916
fold: 0 - cp:9 train: 0.9164034164034163 test: f1=0.8390011293763332, acc=0.924948815443112
fold: 0 - cp:10 train: 0.9157599157599158 test: f1=0.8371568258743889, acc=0.9240128692600176
fold: 0 - cp:11 train: 0.9565344565344565 test: f1=0.9234802147047809, acc=0.9641415618601931
fold: 0 - cp:12 train: 0.9629109629109629 test: f1=0.9350460494425594, acc=0.9686458028663352
fold: 0 - cp:13 train: 0.9735872235872237 test: f1=0.9601545520405699, acc=0.9806961099736765
fold: 0 - cp:14 train: 0.9798467298467298 test: f1=0.971539299987889, acc=0.9862532904357999
fold: 0 - cp:15 train: 0.9801099801099801 test: f1=0.9755329457364341, acc=0.9881836794384323
fold: 0 - cp:16 train: 0.9782379782379782 test: f1=0.9754039064383893, acc=0.9880666861655455
fold: 0 - cp:17 train: 0.9796127296127296 test: f1=0.9739677927109819, acc=0.987423223164668
fold: 0 - cp:18 train: 0.98010998010998 test: f1=0.9755625453665618, acc=0.9881836794384323
fold: 0 - cp:19 train: 0.9806072306072307 test: f1=0.9708503974945797, acc=0.9858438139806961
fold: 1 - cp:1 train: 0.8019888678522277 test: f1=0.5385363144007778, acc=0.8056043056043056
fold: 1 - cp:2 train: 0.8189236424496135 test: f1=0.5510688836104513, acc=0.8230958230958231
fold: 1 - cp:3 train: 0.8422345367537226 test: f1=0.7017587012667569, acc=0.8581373581373581
fold: 1 - cp:4 train: 0.8354198034825082 test: f1=0.6939229249011858, acc=0.855036855036855
fold: 1 - cp:5 train: 0.8298626264232254 test: f1=0.6632589452686697, acc=0.841991341991342
fold: 1 - cp:6 train: 0.8986836713497921 test: f1=0.797123391370174, acc=0.905931905931906
fold: 1 - cp:7 train: 0.9231646044643237 test: f1=0.8569330559295067, acc=0.9316134316134316
fold: 1 - cp:8 train: 0.9176366603250086 test: f1=0.8433855799373041, acc=0.926933426933427
fold: 1 - cp:9 train: 0.9181046197307311 test: f1=0.8476738369184592, acc=0.9287469287469288
fold: 1 - cp:10 train: 0.9183971473980833 test: f1=0.8451903807615231, acc=0.9276939276939277
fold: 1 - cp:11 train: 0.9587306450900274 test: f1=0.9295426452410382, acc=0.9666549666549666
fold: 1 - cp:12 train: 0.9657794401886587 test: f1=0.9405313185474043, acc=0.9714519714519715
fold: 1 - cp:13 train: 0.9820999847029328 test: f1=0.9684848484848485, acc=0.9847899847899848
fold: 1 - cp:14 train: 0.9830943796198827 test: f1=0.9719353662981411, acc=0.9864864864864865
fold: 1 - cp:15 train: 0.9826265399791371 test: f1=0.9664608306090327, acc=0.9837954837954838
fold: 1 - cp:16 train: 0.9836794452201565 test: f1=0.9710548625408744, acc=0.9860184860184861
fold: 1 - cp:17 train: 0.9818367926112428 test: f1=0.9726524685382382, acc=0.9867789867789868
fold: 1 - cp:18 train: 0.9830651946059059 test: f1=0.9649358582773365, acc=0.9832104832104832
fold: 1 - cp:19 train: 0.9826850023972158 test: f1=0.9710688778598232, acc=0.9860184860184861
fold: 2 - cp:1 train: 0.8055458055458056 test: f1=0.5219957835558678, acc=0.8010529394559813
fold: 2 - cp:2 train: 0.8236808236808236 test: f1=0.5467775467775469, acc=0.8214682655747294
fold: 2 - cp:3 train: 0.8254358254358255 test: f1=0.5710157491691952, acc=0.826323486399532
fold: 2 - cp:4 train: 0.8267520767520767 test: f1=0.5611382836816363, acc=0.8267914594910792
fold: 2 - cp:5 train: 0.8285363285363286 test: f1=0.6619083395942901, acc=0.8420590816028078
fold: 2 - cp:6 train: 0.8903123903123903 test: f1=0.7871566537062586, acc=0.9007312079555425
fold: 2 - cp:7 train: 0.9224289224289224 test: f1=0.8433298862461219, acc=0.9291020766305937
fold: 2 - cp:8 train: 0.9244764244764245 test: f1=0.8463604963541, acc=0.9297455396314712
fold: 2 - cp:9 train: 0.9200889200889201 test: f1=0.8418737060041408, acc=0.9285171102661597
fold: 2 - cp:10 train: 0.9218439218439217 test: f1=0.8324310389275587, acc=0.9239543726235742
fold: 2 - cp:11 train: 0.958991458991459 test: f1=0.9267633325141312, acc=0.9651360046797309
fold: 2 - cp:12 train: 0.9606587106587107 test: f1=0.9367613013281345, acc=0.969640245685873
fold: 2 - cp:13 train: 0.9754007254007253 test: f1=0.960648988981717, acc=0.9809885931558935
fold: 2 - cp:14 train: 0.9787937287937288 test: f1=0.9654000242806848, acc=0.9833284586136297
fold: 2 - cp:15 train: 0.9775359775359777 test: f1=0.9691470054446462, acc=0.9850833577069319
fold: 2 - cp:16 train: 0.9792909792909794 test: f1=0.9661777185113347, acc=0.9836794384322901
fold: 2 - cp:17 train: 0.9797882297882298 test: f1=0.9678433268858802, acc=0.9844398947060544
fold: 2 - cp:18 train: 0.9786182286182287 test: f1=0.9683651291958465, acc=0.984673881251828
fold: 2 - cp:19 train: 0.9793787293787294 test: f1=0.9701204819277107, acc=0.9854928341620357
fold: 3 - cp:1 train: 0.8036852908460301 test: f1=0.5345858240819812, acc=0.8087048087048087
fold: 3 - cp:2 train: 0.8143608329324287 test: f1=0.5493587831792425, acc=0.8232128232128232
fold: 3 - cp:3 train: 0.8228430129167144 test: f1=0.6121540814907523, acc=0.8368433368433369
fold: 3 - cp:4 train: 0.8316172278210181 test: f1=0.6892039258451472, acc=0.84994734994735
fold: 3 - cp:5 train: 0.8264405509375092 test: f1=0.6813432835820896, acc=0.8501228501228502
fold: 3 - cp:6 train: 0.8899677990985899 test: f1=0.7781716890351987, acc=0.8975078975078975
fold: 3 - cp:7 train: 0.9159404802830166 test: f1=0.8513243378310844, acc=0.9303849303849304
fold: 3 - cp:8 train: 0.9127521552357771 test: f1=0.8301597444089457, acc=0.9222534222534222
fold: 3 - cp:9 train: 0.910938896374086 test: f1=0.8361753189339397, acc=0.9241254241254241
fold: 3 - cp:10 train: 0.9132202617813288 test: f1=0.8490147783251232, acc=0.9282789282789283
fold: 3 - cp:11 train: 0.9564784681186178 test: f1=0.9249628528974739, acc=0.9645489645489645
fold: 3 - cp:12 train: 0.9654578472723069 test: f1=0.9395759284226007, acc=0.9711594711594712
fold: 3 - cp:13 train: 0.9830944651662948 test: f1=0.9744273421403467, acc=0.9876564876564876
fold: 3 - cp:14 train: 0.9842059115280922 test: f1=0.9752787203102277, acc=0.9880659880659881
fold: 3 - cp:15 train: 0.9865749962263767 test: f1=0.9765861943467186, acc=0.9887094887094887
fold: 3 - cp:16 train: 0.9839718736536706 test: f1=0.973530840213696, acc=0.9872469872469872
fold: 3 - cp:17 train: 0.9823339883587895 test: f1=0.975018190637885, acc=0.987948987948988
fold: 3 - cp:18 train: 0.9831237665233922 test: f1=0.9764791464597479, acc=0.9886509886509887
fold: 3 - cp:19 train: 0.9827726566729842 test: f1=0.9768905021173624, acc=0.9888264888264888
fold: 0 - cp:19 train: 0.9897302567435815 test: f1=0.97128894318876, acc=0.9862532904357999
fold: 1 - cp:19 train: 0.990510237244069 test: f1=0.9787750151607034, acc=0.9897630886224043
fold: 2 - cp:19 train: 0.9895027624309393 test: f1=0.9818621523579202, acc=0.9912255045334893
fold: 3 - cp:19 train: 0.9890152746181344 test: f1=0.9813140446051839, acc=0.9909330213512723
fold: 4 - cp:19 train: 0.9889827754306143 test: f1=0.9758162031438936, acc=0.988300672711319
fold: 5 - cp:19 train: 0.9887552811179721 test: f1=0.9769975786924939, acc=0.9888856390757531
fold: 6 - cp:19 train: 0.9901202469938252 test: f1=0.9817961165048543, acc=0.9912255045334893
fold: 7 - cp:19 train: 0.9888852778680534 test: f1=0.9860690490611751, acc=0.9932728868090085
fold: 8 - cp:19 train: 0.9897627559311017 test: f1=0.9855072463768116, acc=0.9929804036267914
fold: 9 - cp:19 train: 0.9886256011241045 test: f1=0.9752265861027191, acc=0.9880046811000586



PC8
Features:
	workclass_Local-gov workclass_Never-worked
	workclass_Never-worked^2
	marital-status_Married-AF-spouse
	workclass_?^2

PC4
Features:
	workclass_Local-gov workclass_Never-workeddot: graph is too large for cairo-renderer bitmaps. Scaling by 0.370999 to fit

	workclass_Never-worked
	occupation_Armed-Forces
	occupation_Adm-clerical

PC14
Features:
	workclass_Local-gov workclass_Never-worked
	workclass_Never-worked
	occupation_Armed-Forces
	marital-status_Married-AF-spouse

PC9
Features:
	workclass_Local-gov workclass_Never-worked
	marital-status_Separated
	workclass_Never-worked
	occupation_Armed-Forces

PC19
Features:
	workclass_Local-gov workclass_Never-worked
	workclass_Never-worked
	workclass_State-gov
	workclass_Without-pay

PC2
Features:
	workclass_Local-gov workclass_Never-worked
	workclass_Without-pay
	occupation_Farming-fishing
	workclass_Never-worked

PC16
Features:
	workclass_Local-gov workclass_Never-worked
	workclass_Never-worked
	occupation_Armed-Forces
	workclass_Without-pay

PC10
Features:
	workclass_Local-gov workclass_Never-worked
	workclass_Never-worked
	occupation_Armed-Forces
	marital-status_Married-AF-spouse

PC5
Features:
	workclass_Local-gov workclass_Never-worked
	workclass_Without-pay
	workclass_Never-worked
	marital-status_Married-AF-spouse

PC3
Features:
	workclass_Local-gov workclass_Never-worked
	occupation_Armed-Forces
	marital-status_Married-spouse-absent
	workclass_Without-pay

PC18
Features:
	workclass_Local-gov workclass_Never-worked
	occupation_Armed-Forces
	workclass_Never-worked
	workclass_Without-pay

PC17
Features:
	workclass_Local-gov workclass_Never-worked
	marital-status_Married-AF-spouse
	relationship_Not-in-family
	occupation_Armed-Forces

PC7
Features:
	workclass_Local-gov workclass_Never-worked
	workclass_Never-worked^2
	workclass_Never-worked
	workclass_Without-pay

PC15
Features:
	workclass_Local-gov workclass_Never-worked
	marital-status_Married-AF-spouse
	race_Amer-Indian-Eskimo
	workclass_Never-worked

PC6
Features:
	workclass_Local-gov workclass_Never-worked
	workclass_Never-worked
	race_Asian-Pac-Islander
	workclass_Without-pay

PC12
Features:
	workclass_Local-gov workclass_Never-worked
	workclass_Without-pay
	marital-status_Married-AF-spouse
	workclass_Never-worked

PC13
Features:
	workclass_Local-gov workclass_Never-worked
	workclass_Never-worked
	occupation_Priv-house-serv
	race_Other

PC11
Features:
	workclass_Local-gov workclass_Never-worked
	workclass_Never-worked
	occupation_Armed-Forces
	marital-status_Married-AF-spouse

PC1
Features:
	workclass_Local-gov workclass_Never-worked
	occupation_Armed-Forces
	workclass_Without-pay
	marital-status_Married-AF-spouse

Normalized confusion matrix
[[9.99228395e-01 7.71604938e-04]
 [4.84261501e-03 9.95157385e-01]]

              precision    recall  f1-score   support

           0       1.00      1.00      1.00      2592
           1       1.00      1.00      1.00       826

    accuracy                           1.00      3418
   macro avg       1.00      1.00      1.00      3418
weighted avg       1.00      1.00      1.00      3418

Traceback (most recent call last):
  File "decision-tree-f1-98-acc-99-auc-99.py", line 386, in <module>
    sklearn.experimental.dump(best_model, 'lgr.sklearn.experimental')
AttributeError: module 'sklearn' has no attribute 'experimental'
