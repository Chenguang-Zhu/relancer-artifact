No handles with labels found to put in legend.
No handles with labels found to put in legend.
['heart.csv']
Data First 5 Rows Show

Data Last 5 Rows Show

Data Show Describe

Data Show Info

<class 'pandas.core.frame.DataFrame'>
RangeIndex: 303 entries, 0 to 302
Data columns (total 14 columns):
 #   Column    Non-Null Count  Dtype  
---  ------    --------------  -----  
 0   age       303 non-null    int64  
 1   sex       303 non-null    int64  
 2   cp        303 non-null    int64  
 3   trestbps  303 non-null    int64  
 4   chol      303 non-null    int64  
 5   fbs       303 non-null    int64  
 6   restecg   303 non-null    int64  
 7   thalach   303 non-null    int64  
 8   exang     303 non-null    int64  
 9   oldpeak   303 non-null    float64
 10  slope     303 non-null    int64  
 11  ca        303 non-null    int64  
 12  thal      303 non-null    int64  
 13  target    303 non-null    int64  
dtypes: float64(1), int64(13)
memory usage: 33.3 KB
Data Show Columns:

Data Shape Show

Data Sum of Null Values 








Min Age : 29
Max Age : 77
Mean Age : 54.366336633663366
Young Ages : 16
Middle Ages : 128
Elderly Ages : 151










Total Genders : 303
Male Count    : 207
Female Count  : 96
Male State: 68.32%
Female State: 31.68%


















Target 1 Thal 0:  1
Target 1 Thal 1:  6
Target 1 Thal 2:  130
Target 1 Thal 3:  28
**************************************************
Target 0 Thal 0:  1
Target 0 Thal 1:  12
Target 0 Thal 2:  36
Target 0 Thal 3:  89







8
55
30


X_train (242, 14)
X_test (61, 14)
y_train (242,)
y_test (61,)
[0.25069557 0.17935193 0.12879318 0.09556117 0.07603197 0.06460611
 0.05580481 0.04257635 0.02999253 0.02360139 0.02075818 0.0156925
 0.01026596 0.00626834]

['Age', 'Sex', 'Cp', 'Trestbps', 'Chol', 'Fbs', 'Restecg', 'Thalach', 'Exang', 'Oldpeak', 'Slope', 'Ca', 'Thal', 'AgeRange']
[[ 8.81347322e-02  4.65342239e-01 -3.12452745e-01  1.31979053e-02
  -2.64386397e-03  1.94504864e-02 -3.71456984e-02 -1.75249277e-01
   7.17707790e-01  1.68676245e-01 -2.23545648e-01  1.20887016e-01
   1.28737326e-01  1.43856767e-01]
 [ 1.62605861e-01 -8.54520916e-01 -2.04167585e-01  6.49323130e-02
   6.97159523e-02 -2.53324239e-02 -7.27306422e-03 -1.29131596e-01
   3.18807628e-01  4.99567080e-02 -1.41977238e-01 -5.38494882e-03
  -3.12811740e-02  2.23436334e-01]
 [ 3.23243751e-01  1.05671125e-01  2.09016455e-01  1.17663387e-01
   3.88361436e-02  5.11356159e-01 -2.02594772e-01 -7.34055729e-02
  -2.67149471e-01  5.70813735e-02 -1.18879224e-01  2.18032882e-01
  -2.85637322e-02  6.16664038e-01]
 [-1.65405805e-01 -1.06315939e-01  4.98120560e-01  5.24303442e-02
  -1.58249854e-02  6.14881787e-01  7.34197833e-02  6.04270565e-02
   3.61726569e-01  2.82122497e-02 -1.55670437e-01 -1.81326619e-01
  -3.45369842e-02 -3.64890941e-01]
 [-6.80302758e-03  1.47337086e-02  2.24759957e-01 -3.24429274e-02
  -3.41407924e-02 -3.11704285e-01  9.87897786e-02 -1.07643734e-01
  -2.35386839e-01  3.48461538e-01 -8.03566320e-01 -4.68999189e-02
   1.35491646e-03 -6.11770361e-02]
 [-1.31253505e-01 -3.64387932e-02 -6.55196290e-01 -1.10620013e-02
  -7.79399013e-03  4.88316662e-01  2.42135522e-01 -2.72372475e-02
  -3.16668152e-01  7.28393312e-02 -2.03181195e-01  1.76153799e-01
   4.71592272e-02 -2.72091454e-01]
 [ 1.38045727e-01  1.02795636e-02  2.01378124e-01  1.12154874e-02
  -4.36920652e-02 -4.77546999e-02  9.00345234e-01 -7.46967320e-02
   5.16786589e-02  3.49304776e-02  1.70475172e-01  2.32681962e-01
   8.68889546e-02  1.58508456e-01]
 [-5.69792233e-02 -1.14387390e-01  1.89334222e-01  1.64615873e-02
   1.76006297e-02 -9.27964324e-02 -2.38410562e-01 -7.21389846e-02
   4.44457167e-02  1.69785780e-01  1.00301808e-01  8.59984215e-01
   5.86119637e-04 -3.10079979e-01]
 [-4.09760085e-02  6.62115956e-02 -3.69645660e-02 -2.32324913e-01
  -1.78090458e-01  7.20538549e-03  6.62828816e-02 -2.36977391e-01
   6.14484897e-02 -1.94150434e-01 -6.51146605e-02  7.56983947e-02
  -8.91037223e-01  2.98011427e-02]
 [ 9.64365862e-02  7.43255890e-02 -7.20101714e-02  8.55560390e-01
   1.13061054e-01 -7.57258213e-02  4.31402934e-02  5.97691718e-02
  -1.96390083e-02  2.76470195e-01  1.07307643e-01 -8.79748541e-02
  -3.35921625e-01 -1.23031305e-01]
 [ 1.04005136e-01  6.40258621e-03  5.83518757e-02  5.98687704e-03
  -3.48565703e-02  4.33849455e-02 -7.26592712e-02 -8.89828407e-01
  -1.28515809e-01  1.28679870e-01  2.29941496e-01 -2.06391236e-01
   1.52909916e-01 -1.83311918e-01]
 [-2.98138380e-02 -1.01370359e-02 -2.49083191e-02 -4.02129006e-01
   2.93640681e-01  6.72162842e-02  3.15167990e-03  1.52911403e-01
  -4.34890700e-03  7.63437738e-01  2.85304264e-01 -1.34088421e-01
  -1.88670802e-01  6.86623109e-02]
 [ 2.50082070e-01  7.66845116e-02  2.34419071e-02 -8.32610912e-02
   8.78956704e-01 -2.22488833e-02  5.77348518e-02 -6.73781260e-02
  -3.06387189e-03 -3.05490472e-01 -1.23548405e-01  2.62582875e-02
  -6.68303790e-02 -1.71492460e-01]
 [ 8.42106263e-01  1.06579011e-02 -3.93746421e-02 -1.51029393e-01
  -2.92275845e-01  1.51389781e-02 -3.74820610e-02  2.02517404e-01
   2.06519506e-03  3.70108075e-02  9.48229424e-03 -5.70944505e-02
  -2.07015085e-02 -3.64908675e-01]]



('Dim1', 'Dim2', 'Dim3')
**************************************************
Best parameters set:
{'C': 0.1, 'penalty': 'l2', 'random_state': 0}

Train Classification Report:
**************************************************
              precision    recall  f1-score   support

           0       0.80      0.62      0.70       109
           1       0.74      0.87      0.80       133

    accuracy                           0.76       242
   macro avg       0.77      0.75      0.75       242
weighted avg       0.77      0.76      0.76       242

**************************************************
Train Confusion Matrix:
[[ 68  41]
 [ 17 116]]
**************************************************
Test Classification Report:
**************************************************
              precision    recall  f1-score   support

           0       0.83      0.69      0.75        29
           1       0.76      0.88      0.81        32

    accuracy                           0.79        61
   macro avg       0.80      0.78      0.78        61
weighted avg       0.79      0.79      0.78        61

**************************************************
Test Confusion Matrix:
[[20  9]
 [ 4 28]]
**************************************************
**************************************************
0.8101190476190476
0.07789587527418683
**************************************************
('Dim4', 'Dim5', 'Dim5', 'Dim6')
**************************************************
Best parameters set:
{'C': 0.1, 'penalty': 'l2', 'random_state': 0}

Train Classification Report:
**************************************************
              precision    recall  f1-score   support

           0       0.56      0.17      0.26       109
           1       0.57      0.89      0.69       133

    accuracy                           0.57       242
   macro avg       0.56      0.53      0.47       242
weighted avg       0.56      0.57      0.50       242

**************************************************
Train Confusion Matrix:
[[ 18  91]
 [ 14 119]]
**************************************************
Test Classification Report:
**************************************************
              precision    recall  f1-score   support

           0       0.31      0.14      0.19        29
           1       0.48      0.72      0.57        32

    accuracy                           0.44        61
   macro avg       0.39      0.43      0.38        61
weighted avg       0.40      0.44      0.39        61

**************************************************
Test Confusion Matrix:
[[ 4 25]
 [ 9 23]]
**************************************************
**************************************************
0.8101190476190476
0.07789587527418683
**************************************************
('Dim7', 'Dim8', 'Dim1')
**************************************************
Best parameters set:
{'C': 0.1, 'penalty': 'l2', 'random_state': 0}

Train Classification Report:
**************************************************
              precision    recall  f1-score   support

           0       0.81      0.62      0.70       109
           1       0.74      0.88      0.80       133

    accuracy                           0.76       242
   macro avg       0.78      0.75      0.75       242
weighted avg       0.77      0.76      0.76       242

**************************************************
Train Confusion Matrix:
[[ 68  41]
 [ 16 117]]
**************************************************
Test Classification Report:
**************************************************
              precision    recall  f1-score   support

           0       0.84      0.72      0.78        29
           1       0.78      0.88      0.82        32

    accuracy                           0.80        61
   macro avg       0.81      0.80      0.80        61
weighted avg       0.81      0.80      0.80        61

**************************************************
Test Confusion Matrix:
[[21  8]
 [ 4 28]]
**************************************************
**************************************************
0.8101190476190476
0.07789587527418683
**************************************************
('Dim4', 'Dim8', 'Dim5')
**************************************************
Best parameters set:
{'C': 0.5, 'penalty': 'l2', 'random_state': 0}

Train Classification Report:
**************************************************
              precision    recall  f1-score   support

           0       0.69      0.33      0.45       109
           1       0.62      0.88      0.72       133

    accuracy                           0.63       242
   macro avg       0.65      0.60      0.59       242
weighted avg       0.65      0.63      0.60       242

**************************************************
Train Confusion Matrix:
[[ 36  73]
 [ 16 117]]
**************************************************
Test Classification Report:
**************************************************
              precision    recall  f1-score   support

           0       0.35      0.21      0.26        29
           1       0.48      0.66      0.55        32

    accuracy                           0.44        61
   macro avg       0.42      0.43      0.41        61
weighted avg       0.42      0.44      0.41        61

**************************************************
Test Confusion Matrix:
[[ 6 23]
 [11 21]]
**************************************************
**************************************************
0.8101190476190476
0.07789587527418683
**************************************************
Traceback (most recent call last):
  File "analyzing-the-heart-disease.py", line 1171, in <module>
    lr.fit(X_train,y_train)
  File "/home/cgzhu/anaconda3/envs/migration-plus/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py", line 1304, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File "/home/cgzhu/anaconda3/envs/migration-plus/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py", line 443, in _check_solver
    "got %s penalty." % (solver, penalty))
ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.
