fold: 0 - cp:1 train: 0.805019305019305 test: f1=0.56796443486461, acc=0.8124012869260018
fold: 0 - cp:2 train: 0.813882063882064 test: f1=0.5597338733005496, acc=0.8219362386662767
fold: 0 - cp:3 train: 0.8224523224523224 test: f1=0.6467050864445002, acc=0.8350394852295993
fold: 0 - cp:4 train: 0.8261085761085761 test: f1=0.652969180656477, acc=0.8379643170517695
fold: 0 - cp:5 train: 0.8278343278343279 test: f1=0.6671621454230149, acc=0.842819537876572
fold: 0 - cp:6 train: 0.8927401427401427 test: f1=0.7881485249237029, acc=0.9025446036852881
fold: 0 - cp:7 train: 0.9164034164034165 test: f1=0.8461827754795036, acc=0.9282246270839427
fold: 0 - cp:8 train: 0.9172516672516673 test: f1=0.8433341702234497, acc=0.9269961977186312
fold: 0 - cp:9 train: 0.9120744120744121 test: f1=0.8316142341413099, acc=0.9236033928049138
fold: 0 - cp:10 train: 0.9152626652626653 test: f1=0.8445006321112516, acc=0.9280491371746125
fold: 0 - cp:11 train: 0.9544577044577045 test: f1=0.9211913224659884, acc=0.9623866627668909
fold: 0 - cp:12 train: 0.9594887094887096 test: f1=0.9303519061583578, acc=0.9666569172272594
fold: 0 - cp:13 train: 0.9841464841464842 test: f1=0.9720169594185343, acc=0.9864872769815736
fold: 0 - cp:14 train: 0.9811922311922311 test: f1=0.9676562877142167, acc=0.9843229014331676
fold: 0 - cp:15 train: 0.9830057330057329 test: f1=0.9755801239217593, acc=0.9882421760748757
fold: 0 - cp:16 train: 0.9837662337662337 test: f1=0.9741159314619029, acc=0.9875402164375549
fold: 0 - cp:17 train: 0.982069732069732 test: f1=0.9735308402136961, acc=0.9872477332553378
fold: 0 - cp:18 train: 0.9846729846729847 test: f1=0.9758875560402278, acc=0.9883591693477625
fold: 0 - cp:19 train: 0.9842927342927343 test: f1=0.9727550397067808, acc=0.9869552500731208
fold: 1 - cp:1 train: 0.8027493138630247 test: f1=0.5015946651203247, acc=0.7988767988767989
fold: 1 - cp:2 train: 0.8181046176776172 test: f1=0.5347355947267072, acc=0.8162513162513163
fold: 1 - cp:3 train: 0.8223747900280423 test: f1=0.660729746444032, acc=0.8395343395343395
fold: 1 - cp:4 train: 0.8240128361501783 test: f1=0.6307306117056415, acc=0.8364923364923365
fold: 1 - cp:5 train: 0.8262650165434442 test: f1=0.6251334044823905, acc=0.8356148356148356
fold: 1 - cp:6 train: 0.8883008348672832 test: f1=0.7900435594275047, acc=0.9013104013104013
fold: 1 - cp:7 train: 0.9197720014285292 test: f1=0.8540364908772806, acc=0.9316719316719316
fold: 1 - cp:8 train: 0.9170223583829106 test: f1=0.8569325153374232, acc=0.9317889317889317
fold: 1 - cp:9 train: 0.916262097152364 test: f1=0.8526420243115851, acc=0.9305019305019305
fold: 1 - cp:10 train: 0.9128986654431203 test: f1=0.8478533768516193, acc=0.9290979290979291
fold: 1 - cp:11 train: 0.9586136210200319 test: f1=0.9219578350388362, acc=0.962969462969463
fold: 1 - cp:12 train: 0.9679146067774986 test: f1=0.9392574558734023, acc=0.9708084708084708
fold: 1 - cp:13 train: 0.9806375722087 test: f1=0.972232326906754, acc=0.9866034866034866
fold: 1 - cp:14 train: 0.97829784019536 test: f1=0.9662676822633297, acc=0.9836784836784837
fold: 1 - cp:15 train: 0.9793506325151154 test: f1=0.9694049626596002, acc=0.9851409851409851
fold: 1 - cp:16 train: 0.9778004117615723 test: f1=0.968454258675079, acc=0.9847899847899848
fold: 1 - cp:17 train: 0.9789704642594207 test: f1=0.971718636693256, acc=0.9863109863109863
fold: 1 - cp:18 train: 0.9807254009991493 test: f1=0.972874788084282, acc=0.9868959868959869
fold: 1 - cp:19 train: 0.9804913494373017 test: f1=0.9697921701304979, acc=0.9853749853749854
fold: 2 - cp:1 train: 0.7977360477360478 test: f1=0.5265103056147832, acc=0.8051477040070196
fold: 2 - cp:2 train: 0.8372528372528373 test: f1=0.6517700901871045, acc=0.8486692015209125
fold: 2 - cp:3 train: 0.8395343395343395 test: f1=0.6809210526315789, acc=0.8524714828897338
fold: 2 - cp:4 train: 0.8344448344448344 test: f1=0.6809295462928808, acc=0.8482012284293653
fold: 2 - cp:5 train: 0.8262840762840762 test: f1=0.6386257420740179, acc=0.8326411231354197
fold: 2 - cp:6 train: 0.8888791388791389 test: f1=0.7909114117947409, acc=0.9041825095057034
fold: 2 - cp:7 train: 0.9195039195039195 test: f1=0.8561024610748368, acc=0.9329628546358585
fold: 2 - cp:8 train: 0.9201181701181701 test: f1=0.8549196787148594, acc=0.9323778882714244
fold: 2 - cp:9 train: 0.918041418041418 test: f1=0.8556324732536187, acc=0.9329043579994151
fold: 2 - cp:10 train: 0.9148824148824148 test: f1=0.8448984676716084, acc=0.9271716876279614
fold: 2 - cp:11 train: 0.9585234585234585 test: f1=0.9292679916059745, acc=0.9664814273179292
fold: 2 - cp:12 train: 0.9646367146367146 test: f1=0.9446269928197639, acc=0.973384030418251
fold: 2 - cp:13 train: 0.9797589797589796 test: f1=0.9692717154609243, acc=0.9851418543433752
fold: 2 - cp:14 train: 0.9812799812799812 test: f1=0.9680708995993687, acc=0.9846153846153847
fold: 2 - cp:15 train: 0.9808997308997309 test: f1=0.9699903194578896, acc=0.9854928341620357
fold: 2 - cp:16 train: 0.9804609804609805 test: f1=0.9693667514226904, acc=0.9852003509798186
fold: 2 - cp:17 train: 0.9801684801684802 test: f1=0.9750484496124031, acc=0.9879496928926587
fold: 2 - cp:18 train: 0.9816602316602316 test: f1=0.9719830200121286, acc=0.9864872769815736
fold: 2 - cp:19 train: 0.9806657306657307 test: f1=0.9708667152221413, acc=0.9859608072535829
fold: 3 - cp:1 train: 0.8102661368045084 test: f1=0.5167630057803468, acc=0.8043758043758044
fold: 3 - cp:2 train: 0.8189528000887383 test: f1=0.5385743619829861, acc=0.8159588159588159
fold: 3 - cp:3 train: 0.8254459130687488 test: f1=0.6220218931101094, acc=0.8283023283023283
fold: 3 - cp:4 train: 0.8228719549788805 test: f1=0.6275163482497756, acc=0.8300573300573301
fold: 3 - cp:5 train: 0.8256801186141384 test: f1=0.6494978109708988, acc=0.8407628407628408
fold: 3 - cp:6 train: 0.8920441747711284 test: f1=0.7775187775187774, acc=0.8994968994968995
fold: 3 - cp:7 train: 0.9146825921510058 test: f1=0.8485985985985987, acc=0.9292149292149292
fold: 3 - cp:8 train: 0.9159988366235442 test: f1=0.8464410154305625, acc=0.9278109278109278
fold: 3 - cp:9 train: 0.911289859084665 test: f1=0.833063209076175, acc=0.9216684216684217
fold: 3 - cp:10 train: 0.9132200427825136 test: f1=0.8427106776694173, acc=0.9264069264069265
fold: 3 - cp:11 train: 0.9548991034133758 test: f1=0.9251500673771897, acc=0.9642564642564643
fold: 3 - cp:12 train: 0.9608364863687746 test: f1=0.9312027323737496, acc=0.967005967005967
fold: 3 - cp:13 train: 0.9832699174358042 test: f1=0.9713104789691221, acc=0.9861939861939862
fold: 3 - cp:14 train: 0.9830650816846418 test: f1=0.971504789620468, acc=0.9862524862524863
fold: 3 - cp:15 train: 0.9813687921432422 test: f1=0.9723502304147466, acc=0.9866619866619867
fold: 3 - cp:16 train: 0.9827142490046094 test: f1=0.9737637528714786, acc=0.9873054873054873
fold: 3 - cp:17 train: 0.9789120668566154 test: f1=0.9734770497759477, acc=0.9871884871884872
fold: 3 - cp:18 train: 0.9802574552808525 test: f1=0.9679533867443555, acc=0.9845559845559846
fold: 3 - cp:19 train: 0.9818951900140482 test: f1=0.9707559762164786, acc=0.9859014859014859
fold: 0 - cp:18 train: 0.9891452713682158 test: f1=0.9782345828295043, acc=0.9894706054401872
fold: 1 - cp:18 train: 0.989795255118622 test: f1=0.9719512195121951, acc=0.986545773618017
fold: 2 - cp:18 train: 0.988852778680533 test: f1=0.978953698135899, acc=0.9897630886224043
fold: 3 - cp:18 train: 0.9882677933051675 test: f1=0.9813365442504516, acc=0.9909330213512723
fold: 4 - cp:18 train: 0.9898602534936625 test: f1=0.9787750151607034, acc=0.9897630886224043
fold: 5 - cp:18 train: 0.9877153071173221 test: f1=0.9778310365488316, acc=0.9891781222579702
fold: 6 - cp:18 train: 0.9888852778680534 test: f1=0.9805825242718446, acc=0.9906405381690553
fold: 7 - cp:18 train: 0.9896652583685407 test: f1=0.97632058287796, acc=0.9885931558935361
fold: 8 - cp:18 train: 0.9886252843678909 test: f1=0.974390243902439, acc=0.9877157063468851
fold: 9 - cp:18 train: 0.9898280710623559 test: f1=0.9781818181818182, acc=0.9894675248683441



PC18
Features:
	workclass_Local-gov workclass_Never-worked
	marital-status_Married-AF-spouse
	workclass_Never-worked
	occupation_Armed-Forces

PC9
Features:
	workclass_Local-gov workclass_Never-workeddot: graph is too large for cairo-renderer bitmaps. Scaling by 0.348878 to fit

	workclass_Never-worked
	occupation_Armed-Forces
	workclass_Without-pay

PC4
Features:
	workclass_Local-gov workclass_Never-worked
	workclass_Never-worked
	occupation_Adm-clerical
	occupation_Armed-Forces

PC10
Features:
	workclass_Local-gov workclass_Never-worked
	workclass_Never-worked
	occupation_Other-service
	occupation_Armed-Forces

PC2
Features:
	workclass_Local-gov workclass_Never-worked
	workclass_Without-pay
	workclass_Never-worked
	occupation_Armed-Forces

PC8
Features:
	workclass_Local-gov workclass_Never-worked
	workclass_Never-worked
	marital-status_Married-AF-spouse
	workclass_?^2

PC3
Features:
	workclass_Local-gov workclass_Never-worked
	occupation_Armed-Forces
	marital-status_Married-spouse-absent
	workclass_Without-pay

PC17
Features:
	workclass_Local-gov workclass_Never-worked
	marital-status_Married-spouse-absent
	marital-status_Married-AF-spouse
	occupation_Armed-Forces

PC5
Features:
	workclass_Local-gov workclass_Never-worked
	workclass_Never-worked
	occupation_Armed-Forces
	workclass_Without-pay

PC14
Features:
	workclass_Local-gov workclass_Never-worked
	occupation_Protective-serv
	occupation_Armed-Forces
	workclass_Never-worked

PC16
Features:
	workclass_Local-gov workclass_Never-worked
	race_Asian-Pac-Islander
	workclass_Never-worked
	workclass_Without-pay

PC7
Features:
	workclass_Local-gov workclass_Never-worked
	workclass_Never-worked
	workclass_Without-pay
	occupation_Armed-Forces

PC15
Features:
	workclass_Local-gov workclass_Never-worked
	workclass_Never-worked
	marital-status_Married-AF-spouse
	workclass_Without-pay

PC6
Features:
	workclass_Local-gov workclass_Never-worked
	workclass_Never-worked
	workclass_Without-pay
	occupation_Sales

PC12
Features:
	workclass_Local-gov workclass_Never-worked
	marital-status_Married-spouse-absent
	workclass_Without-pay
	marital-status_Married-AF-spouse

PC13
Features:
	workclass_Local-gov workclass_Never-worked
	workclass_Never-worked
	workclass_Without-pay
	occupation_Armed-Forces

PC11
Features:
	workclass_Local-gov workclass_Never-worked
	occupation_Transport-moving
	workclass_Never-worked
	occupation_Armed-Forces

PC1
Features:
	workclass_Local-gov workclass_Never-worked
	occupation_Armed-Forces
	occupation_Tech-support
	workclass_Without-pay

Normalized confusion matrix
[[9.99228395e-01 7.71604938e-04]
 [4.84261501e-03 9.95157385e-01]]

              precision    recall  f1-score   support

           0       1.00      1.00      1.00      2592
           1       1.00      1.00      1.00       826

    accuracy                           1.00      3418
   macro avg       1.00      1.00      1.00      3418
weighted avg       1.00      1.00      1.00      3418

Traceback (most recent call last):
  File "decision-tree-f1-98-acc-99-auc-99.py", line 383, in <module>
    from sklearn.externals import joblib
ImportError: cannot import name 'joblib'
[Try Solution]: OrderedDict([('action', 'fqn'), ('old_fqn', 'sklearn.externals.joblib'), ('new_fqn', 'joblib'), ('line_no', 383)])fold: 0 - cp:1 train: 0.8044928044928045 test: f1=0.5334434351775392, acc=0.8016964024568587
fold: 0 - cp:2 train: 0.8206973206973207 test: f1=0.5537225649117773, acc=0.8180169640245686
fold: 0 - cp:3 train: 0.8225985725985727 test: f1=0.6251162790697674, acc=0.834980988593156
fold: 0 - cp:4 train: 0.8221598221598222 test: f1=0.6390458254865035, acc=0.8318221702252121
fold: 0 - cp:5 train: 0.8254943254943256 test: f1=0.6554948391013965, acc=0.8340450424100614
fold: 0 - cp:6 train: 0.8927986427986427 test: f1=0.7974349302150132, acc=0.9057619186896754
fold: 0 - cp:7 train: 0.9163449163449164 test: f1=0.8533792933645206, acc=0.9303305059959053
fold: 0 - cp:8 train: 0.9145899145899146 test: f1=0.8350090229440578, acc=0.9251243053524423
fold: 0 - cp:9 train: 0.912981162981163 test: f1=0.8246628131021195, acc=0.9201520912547528
fold: 0 - cp:10 train: 0.9141804141804142 test: f1=0.8416833667334669, acc=0.9260602515355367
fold: 0 - cp:11 train: 0.9593717093717095 test: f1=0.9287918055041343, acc=0.9662474407721556
fold: 0 - cp:12 train: 0.9663039663039663 test: f1=0.9467138153883672, acc=0.9744369698742322
fold: 0 - cp:13 train: 0.9774189774189774 test: f1=0.9696896217264792, acc=0.9853758408891489
fold: 0 - cp:14 train: 0.9796127296127296 test: f1=0.971490698236289, acc=0.9861947937993565
fold: 0 - cp:15 train: 0.9807534807534808 test: f1=0.9744397334948516, acc=0.9876572097104417
fold: 0 - cp:16 train: 0.9805779805779806 test: f1=0.969895605729546, acc=0.9854928341620357
fold: 0 - cp:17 train: 0.9797589797589797 test: f1=0.9697189922480621, acc=0.9853758408891489
fold: 0 - cp:18 train: 0.9807827307827307 test: f1=0.9677341096555071, acc=0.9844398947060544
fold: 0 - cp:19 train: 0.9812214812214812 test: f1=0.9684542586750788, acc=0.9847908745247148
fold: 1 - cp:1 train: 0.8007602673898884 test: f1=0.5118248175182482, acc=0.8043758043758044
fold: 1 - cp:2 train: 0.8213219498022961 test: f1=0.6021912620045989, acc=0.827951327951328
fold: 1 - cp:3 train: 0.836472886660065 test: f1=0.6663409868099659, acc=0.8401778401778401
fold: 1 - cp:4 train: 0.8378765390347047 test: f1=0.6657513729405892, acc=0.8433368433368433
fold: 1 - cp:5 train: 0.8331382567168716 test: f1=0.5855579868708971, acc=0.8338013338013338
fold: 1 - cp:6 train: 0.8936239911614268 test: f1=0.7979456344732556, acc=0.9056394056394056
fold: 1 - cp:7 train: 0.9267038614254337 test: f1=0.8730218068535825, acc=0.9403884403884404
fold: 1 - cp:8 train: 0.9267330361738411 test: f1=0.8675993005246065, acc=0.937989937989938
fold: 1 - cp:9 train: 0.9259138950587243 test: f1=0.8632317914002757, acc=0.9361764361764362
fold: 1 - cp:10 train: 0.9257676620217564 test: f1=0.8543664493031582, acc=0.9333684333684333
fold: 1 - cp:11 train: 0.9607779692009921 test: f1=0.9211050273768044, acc=0.9629109629109629
fold: 1 - cp:12 train: 0.9622111419315443 test: f1=0.9309625996321276, acc=0.967064467064467
fold: 1 - cp:13 train: 0.9820414572695808 test: f1=0.9717732207478891, acc=0.9863109863109863
fold: 1 - cp:14 train: 0.9786779571232076 test: f1=0.9722390592799126, acc=0.9866034866034866
fold: 1 - cp:15 train: 0.9799649481446393 test: f1=0.9673597678916828, acc=0.9842049842049843
fold: 1 - cp:16 train: 0.981398137984474 test: f1=0.9721115537848606, acc=0.9864864864864865
fold: 1 - cp:17 train: 0.979409156526611 test: f1=0.9733720648753328, acc=0.9871299871299871
fold: 1 - cp:18 train: 0.9798187185295281 test: f1=0.9712629799565321, acc=0.9860769860769861
fold: 1 - cp:19 train: 0.9806083632417277 test: f1=0.9740072202166065, acc=0.9873639873639873
fold: 2 - cp:1 train: 0.8099333099333099 test: f1=0.5590474871936868, acc=0.8136882129277566
fold: 2 - cp:2 train: 0.812916812916813 test: f1=0.5575498575498575, acc=0.8183094472067856
fold: 2 - cp:3 train: 0.8211360711360711 test: f1=0.6258360655737705, acc=0.8331090962269669
fold: 2 - cp:4 train: 0.8177138177138177 test: f1=0.6563064691001085, acc=0.8331090962269669
fold: 2 - cp:5 train: 0.8231250731250731 test: f1=0.6446322067594434, acc=0.8326996197718631
fold: 2 - cp:6 train: 0.8897273897273897 test: f1=0.7859044238813537, acc=0.9011991810470897
fold: 2 - cp:7 train: 0.9187141687141687 test: f1=0.8469145074477405, acc=0.9284586136297163
fold: 2 - cp:8 train: 0.9143851643851644 test: f1=0.8401780038143674, acc=0.9264697279906405
fold: 2 - cp:9 train: 0.916169416169416 test: f1=0.8426241941600303, acc=0.9271716876279614
fold: 2 - cp:10 train: 0.9175149175149175 test: f1=0.8369386464263124, acc=0.9245978356244516
fold: 2 - cp:11 train: 0.9587282087282087 test: f1=0.9292481850621386, acc=0.9663644340450425
fold: 2 - cp:12 train: 0.9605124605124605 test: f1=0.9363992172211351, acc=0.9695817490494296
fold: 2 - cp:13 train: 0.973060723060723 test: f1=0.953782534663099, acc=0.9777712781515063
fold: 2 - cp:14 train: 0.982040482040482 test: f1=0.9748877835739415, acc=0.9878911962562152
fold: 2 - cp:15 train: 0.9805779805779805 test: f1=0.969667556418345, acc=0.9853758408891489
fold: 2 - cp:16 train: 0.9814262314262314 test: f1=0.9705061293846341, acc=0.9857853173442527
fold: 2 - cp:17 train: 0.9791447291447292 test: f1=0.9694610049884413, acc=0.9853173442527055
fold: 2 - cp:18 train: 0.9805487305487306 test: f1=0.9714146697482059, acc=0.9862532904357999
fold: 2 - cp:19 train: 0.9813969813969814 test: f1=0.967961992934584, acc=0.9846153846153847
fold: 3 - cp:1 train: 0.7997367695835174 test: f1=0.5162378743146351, acc=0.7987012987012987
fold: 3 - cp:2 train: 0.820678586033055 test: f1=0.6007594250067806, acc=0.8277758277758278
fold: 3 - cp:3 train: 0.8300379897244661 test: f1=0.658802410565457, acc=0.8443313443313444
fold: 3 - cp:4 train: 0.8268792466265559 test: f1=0.6279718422101208, acc=0.8361413361413361
fold: 3 - cp:5 train: 0.8267620275107407 test: f1=0.6109541111559682, acc=0.8308763308763308
fold: 3 - cp:6 train: 0.8908452007422527 test: f1=0.7834580743371812, acc=0.9001404001404001
fold: 3 - cp:7 train: 0.9155600759192242 test: f1=0.8468222442899702, acc=0.9278109278109278
fold: 3 - cp:8 train: 0.9149458116175476 test: f1=0.847, acc=0.9283959283959284
fold: 3 - cp:9 train: 0.9136296903318428 test: f1=0.8362220547601105, acc=0.9237159237159237
fold: 3 - cp:10 train: 0.9150042911449088 test: f1=0.8314462171899125, acc=0.9233649233649234
fold: 3 - cp:11 train: 0.9587891451485274 test: f1=0.9243676742751388, acc=0.9641394641394642
fold: 3 - cp:12 train: 0.9640536747754811 test: f1=0.9369150358575423, acc=0.9696384696384697
fold: 3 - cp:13 train: 0.9785609022565035 test: f1=0.9711330286264134, acc=0.9859599859599859
fold: 3 - cp:14 train: 0.9834162531284666 test: f1=0.9710022861268199, acc=0.9859014859014859
fold: 3 - cp:15 train: 0.9820415257067105 test: f1=0.9746499275712217, acc=0.9877149877149877
fold: 3 - cp:16 train: 0.9823925021047155 test: f1=0.9739004349927501, acc=0.9873639873639873
fold: 3 - cp:17 train: 0.9811932748584596 test: f1=0.9720710917664127, acc=0.9864864864864865
fold: 3 - cp:18 train: 0.9825095569714194 test: f1=0.96944177093359, acc=0.9851409851409851
fold: 3 - cp:19 train: 0.9813395660669876 test: f1=0.9706236455574284, acc=0.9857259857259857
fold: 0 - cp:14 train: 0.9896327591810206 test: f1=0.9854368932038836, acc=0.9929804036267914
fold: 1 - cp:14 train: 0.9893077673058175 test: f1=0.9842233009708738, acc=0.9923954372623575
fold: 2 - cp:14 train: 0.9887552811179721 test: f1=0.9746682750301567, acc=0.9877157063468851
fold: 3 - cp:14 train: 0.9888202794930127 test: f1=0.9765201685731486, acc=0.9885931558935361
fold: 4 - cp:14 train: 0.9889827754306142 test: f1=0.969258589511754, acc=0.9850833577069319
fold: 5 - cp:14 train: 0.9891452713682158 test: f1=0.9765484064942874, acc=0.9885931558935361
fold: 6 - cp:14 train: 0.9887877803054923 test: f1=0.9780755176613886, acc=0.9894706054401872
fold: 7 - cp:14 train: 0.9891127721806955 test: f1=0.9739235900545785, acc=0.987423223164668
fold: 8 - cp:14 train: 0.9882027949301267 test: f1=0.9728424864212432, acc=0.986838256800234
fold: 9 - cp:14 train: 0.9900880223283567 test: f1=0.9789029535864979, acc=0.9897600936220011



PC9
Features:
	workclass_Local-gov workclass_Never-worked
	workclass_Never-worked
	occupation_Armed-Forces
	workclass_Without-pay

PC4
Features:
	workclass_Local-gov workclass_Never-workeddot: graph is too large for cairo-renderer bitmaps. Scaling by 0.372175 to fit

	workclass_Never-worked
	occupation_Armed-Forces
	marital-status_Married-AF-spouse

PC8
Features:
	workclass_Local-gov workclass_Never-worked
	workclass_Federal-gov workclass_Never-worked
	marital-status_Married-AF-spouse
	workclass_?^2

PC14
Features:
	workclass_Local-gov workclass_Never-worked
	marital-status_Married-AF-spouse
	workclass_Never-worked
	occupation_Armed-Forces

PC2
Features:
	workclass_Local-gov workclass_Never-worked
	workclass_Without-pay
	occupation_Armed-Forces
	workclass_Never-worked

PC10
Features:
	workclass_Local-gov workclass_Never-worked
	workclass_Never-worked
	occupation_Armed-Forces
	workclass_Local-gov

PC3
Features:
	workclass_Local-gov workclass_Never-worked
	occupation_Armed-Forces
	workclass_Without-pay
	race_Asian-Pac-Islander

PC7
Features:
	workclass_Local-gov workclass_Never-worked
	workclass_State-gov
	occupation_Armed-Forces
	workclass_Never-worked

PC5
Features:
	workclass_Local-gov workclass_Never-worked
	occupation_Armed-Forces
	workclass_Without-pay
	workclass_Never-worked

PC12
Features:
	workclass_Local-gov workclass_Never-worked
	workclass_Without-pay
	marital-status_Married-AF-spouse
	occupation_Armed-Forces

PC13
Features:
	workclass_Local-gov workclass_Never-worked
	occupation_Armed-Forces
	workclass_Never-worked
	workclass_Without-pay

PC6
Features:
	workclass_Local-gov workclass_Never-worked
	workclass_Never-worked
	workclass_Without-pay
	marital-status_Married-AF-spouse

PC11
Features:
	workclass_Local-gov workclass_Never-worked
	workclass_Never-worked
	occupation_Armed-Forces
	marital-status_Married-AF-spouse

PC1
Features:
	workclass_Local-gov workclass_Never-worked
	occupation_Armed-Forces
	workclass_Without-pay
	marital-status_Married-AF-spouse

Normalized confusion matrix
[[9.99614198e-01 3.85802469e-04]
 [8.47457627e-03 9.91525424e-01]]

              precision    recall  f1-score   support

           0       1.00      1.00      1.00      2592
           1       1.00      0.99      1.00       826

    accuracy                           1.00      3418
   macro avg       1.00      1.00      1.00      3418
weighted avg       1.00      1.00      1.00      3418

[REPAIR EXEC TIME]: 386.47459411621094